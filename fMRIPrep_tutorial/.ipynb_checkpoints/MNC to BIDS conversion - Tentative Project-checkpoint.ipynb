{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNC to BIDS conversion - First Brain Hack School Project\n",
    "## A step-by-step tutorial\n",
    "________________\n",
    "\n",
    "The goal of this tutorial was initially to generate functional connectivity matrices from functional magnetic resonance imaging (fMRI) starting from mnc images. The aim was to first convert the .mnc images in BIDS format. Then, to use fMRIPrep to pre-process the data and use the Nilearn package to extract connectivity matrices from the pre-processed images using different brain parcellations. \n",
    "\n",
    "This project was to be executed with data from the PREVENT-AD, a dataset of participants at risk of Alzheimer's Disease (AD), available openly on the Canadian Open Neuroscience Platform. We wanted to use fMRI data from 10 participants at two different timepoints, at their baseline visit and at their 12 months visit, to obtain two functional connectivity matrices per participants.\n",
    "\n",
    "However, as can be seen below, this project could not be completed. A Jupyter notebook describing how to pre-process the data from a bids dataset is included in this repository.\n",
    "________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The current notebook aims to adress an issue in using .mnc images from the CONP dataset. The code below presents the data to be downloaded using DataLad, then, the minc-toolkit to be downloaded to obtain the mnc2nii tool. Finally, a tentative bash script, mnc2bids, is presented where the intended goal was to process the mnc2nii conversion while setting the output files in bids format. However, as I learned afterwards, the mnc2nii script doesn't produce bids sidecar files (i.e. .json files with parameters), which made it impossible to validate with the bids-validator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. - Presentation of the data (Prevent-AD / CONP)\n",
    "\n",
    "#### 1.1 - Preparation for data download\n",
    "\n",
    "The data used for this project is taken from the Prevent-AD cohort, the data for which is part of the Canadian Open Neuroscience Platform (CONP). The data is accessible [here](https://portal.conp.ca/dataset?id=projects/preventad-open). Note that an account is required for accessing the data. You can gain access by filling the form [here](https://openpreventad.loris.ca/). If you are using your own dataset with fMRIPrep, you can skip ahead to section 2.0 of the tutorial.\n",
    "\n",
    "You can refer to the instructions on the CONP/Prevent-AD for how to download the data. Note that you will require the following to be able to install the dataset on your workstation:\n",
    "- Datalad (you can install Datalad from this [link](http://handbook.datalad.org/en/latest/intro/installation.html)\n",
    "- Git-annex (you can install Git-Annex from this [link](https://git-annex.branchable.com/install/)\n",
    "- Homebrew (in the case where you can't install Git-annex with Conda and you use a Mac, as was my case, you can install it using Homebrew. You can install Homebrew from this [link](https://brew.sh/)\n",
    "\n",
    "With Datalad, you gain access to the full dataset through symbolic links. This means that you will have access to the folders and be able to see what you can download before downloading any actual data. You will need to enter your credentials for the Open PREVENT-AD initiative to download and work with anything. \n",
    "\n",
    "**Be careful:** Note that the full dataset is quite heavy (170.89GB). Datalad gives an option to download all subjects, but only subjects/sessions of interest should be downloaded.\n",
    "\n",
    "The commands used in bash to download the data are provided below for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stong3/Desktop/data_CONP\n",
      "/Users/stong3/Desktop/data_CONP/conp-dataset\n",
      "/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open\n",
      "\u001b[34m1004359\u001b[m\u001b[m   \u001b[34m2424540\u001b[m\u001b[m   \u001b[34m3408795\u001b[m\u001b[m   \u001b[34m4396879\u001b[m\u001b[m   \u001b[34m5456920\u001b[m\u001b[m   \u001b[34m6788676\u001b[m\u001b[m   \u001b[34m7917918\u001b[m\u001b[m   \u001b[34m9522570\u001b[m\u001b[m\n",
      "\u001b[34m1016072\u001b[m\u001b[m   \u001b[34m2448082\u001b[m\u001b[m   \u001b[34m3452929\u001b[m\u001b[m   \u001b[34m4437799\u001b[m\u001b[m   \u001b[34m5458966\u001b[m\u001b[m   \u001b[34m6794127\u001b[m\u001b[m   \u001b[34m7945015\u001b[m\u001b[m   \u001b[34m9539210\u001b[m\u001b[m\n",
      "\u001b[34m1031654\u001b[m\u001b[m   \u001b[34m2484374\u001b[m\u001b[m   \u001b[34m3455156\u001b[m\u001b[m   \u001b[34m4498598\u001b[m\u001b[m   \u001b[34m5558904\u001b[m\u001b[m   \u001b[34m6795892\u001b[m\u001b[m   \u001b[34m8019820\u001b[m\u001b[m   \u001b[34m9555827\u001b[m\u001b[m\n",
      "\u001b[34m1072774\u001b[m\u001b[m   \u001b[34m2496306\u001b[m\u001b[m   \u001b[34m3463254\u001b[m\u001b[m   \u001b[34m4532706\u001b[m\u001b[m   \u001b[34m5562282\u001b[m\u001b[m   \u001b[34m6851811\u001b[m\u001b[m   \u001b[34m8036701\u001b[m\u001b[m   \u001b[34m9566680\u001b[m\u001b[m\n",
      "\u001b[34m1076159\u001b[m\u001b[m   \u001b[34m2623146\u001b[m\u001b[m   \u001b[34m3475739\u001b[m\u001b[m   \u001b[34m4538817\u001b[m\u001b[m   \u001b[34m5692079\u001b[m\u001b[m   \u001b[34m6852929\u001b[m\u001b[m   \u001b[34m8120729\u001b[m\u001b[m   \u001b[34m9584420\u001b[m\u001b[m\n",
      "\u001b[34m1154932\u001b[m\u001b[m   \u001b[34m2631883\u001b[m\u001b[m   \u001b[34m3525262\u001b[m\u001b[m   \u001b[34m4541749\u001b[m\u001b[m   \u001b[34m5707288\u001b[m\u001b[m   \u001b[34m6865719\u001b[m\u001b[m   \u001b[34m8351740\u001b[m\u001b[m   \u001b[34m9605091\u001b[m\u001b[m\n",
      "\u001b[34m1176949\u001b[m\u001b[m   \u001b[34m2663318\u001b[m\u001b[m   \u001b[34m3531206\u001b[m\u001b[m   \u001b[34m4604101\u001b[m\u001b[m   \u001b[34m5730499\u001b[m\u001b[m   \u001b[34m6909468\u001b[m\u001b[m   \u001b[34m8389790\u001b[m\u001b[m   \u001b[34m9650197\u001b[m\u001b[m\n",
      "\u001b[34m1177880\u001b[m\u001b[m   \u001b[34m2738676\u001b[m\u001b[m   \u001b[34m3594014\u001b[m\u001b[m   \u001b[34m4628515\u001b[m\u001b[m   \u001b[34m5774407\u001b[m\u001b[m   \u001b[34m7055352\u001b[m\u001b[m   \u001b[34m8445201\u001b[m\u001b[m   \u001b[34m9690995\u001b[m\u001b[m\n",
      "\u001b[34m1263509\u001b[m\u001b[m   \u001b[34m2757160\u001b[m\u001b[m   \u001b[34m3619481\u001b[m\u001b[m   \u001b[34m4652225\u001b[m\u001b[m   \u001b[34m5817042\u001b[m\u001b[m   \u001b[34m7098391\u001b[m\u001b[m   \u001b[34m8469881\u001b[m\u001b[m   \u001b[34m9742226\u001b[m\u001b[m\n",
      "\u001b[34m1284264\u001b[m\u001b[m   \u001b[34m2823276\u001b[m\u001b[m   \u001b[34m3692881\u001b[m\u001b[m   \u001b[34m4676902\u001b[m\u001b[m   \u001b[34m5836679\u001b[m\u001b[m   \u001b[34m7125565\u001b[m\u001b[m   \u001b[34m8477651\u001b[m\u001b[m   \u001b[34m9742435\u001b[m\u001b[m\n",
      "\u001b[34m1322140\u001b[m\u001b[m   \u001b[34m2843957\u001b[m\u001b[m   \u001b[34m3697357\u001b[m\u001b[m   \u001b[34m4696223\u001b[m\u001b[m   \u001b[34m5984591\u001b[m\u001b[m   \u001b[34m7161471\u001b[m\u001b[m   \u001b[34m8478383\u001b[m\u001b[m   \u001b[34m9748277\u001b[m\u001b[m\n",
      "\u001b[34m1346022\u001b[m\u001b[m   \u001b[34m2864260\u001b[m\u001b[m   \u001b[34m3705605\u001b[m\u001b[m   \u001b[34m4715777\u001b[m\u001b[m   \u001b[34m5985051\u001b[m\u001b[m   \u001b[34m7178383\u001b[m\u001b[m   \u001b[34m8741617\u001b[m\u001b[m   \u001b[34m9769696\u001b[m\u001b[m\n",
      "\u001b[34m1369125\u001b[m\u001b[m   \u001b[34m2887681\u001b[m\u001b[m   \u001b[34m3737955\u001b[m\u001b[m   \u001b[34m4718998\u001b[m\u001b[m   \u001b[34m6008569\u001b[m\u001b[m   \u001b[34m7237992\u001b[m\u001b[m   \u001b[34m8822042\u001b[m\u001b[m   \u001b[34m9779747\u001b[m\u001b[m\n",
      "\u001b[34m1404211\u001b[m\u001b[m   \u001b[34m2924615\u001b[m\u001b[m   \u001b[34m3756689\u001b[m\u001b[m   \u001b[34m4806541\u001b[m\u001b[m   \u001b[34m6161064\u001b[m\u001b[m   \u001b[34m7243782\u001b[m\u001b[m   \u001b[34m8889872\u001b[m\u001b[m   \u001b[34m9827494\u001b[m\u001b[m\n",
      "\u001b[34m1438245\u001b[m\u001b[m   \u001b[34m2963960\u001b[m\u001b[m   \u001b[34m3974587\u001b[m\u001b[m   \u001b[34m4814589\u001b[m\u001b[m   \u001b[34m6187101\u001b[m\u001b[m   \u001b[34m7492583\u001b[m\u001b[m   \u001b[34m8916796\u001b[m\u001b[m   \u001b[34m9843864\u001b[m\u001b[m\n",
      "\u001b[34m1443924\u001b[m\u001b[m   \u001b[34m3017785\u001b[m\u001b[m   \u001b[34m4040157\u001b[m\u001b[m   \u001b[34m4847131\u001b[m\u001b[m   \u001b[34m6245599\u001b[m\u001b[m   \u001b[34m7499557\u001b[m\u001b[m   \u001b[34m8969699\u001b[m\u001b[m   \u001b[34m9865768\u001b[m\u001b[m\n",
      "\u001b[34m1527281\u001b[m\u001b[m   \u001b[34m3047136\u001b[m\u001b[m   \u001b[34m4052945\u001b[m\u001b[m   \u001b[34m4943065\u001b[m\u001b[m   \u001b[34m6265998\u001b[m\u001b[m   \u001b[34m7512043\u001b[m\u001b[m   \u001b[34m9006164\u001b[m\u001b[m   \u001b[34m9870694\u001b[m\u001b[m\n",
      "\u001b[34m1626987\u001b[m\u001b[m   \u001b[34m3048898\u001b[m\u001b[m   \u001b[34m4067832\u001b[m\u001b[m   \u001b[34m4960454\u001b[m\u001b[m   \u001b[34m6350639\u001b[m\u001b[m   \u001b[34m7550757\u001b[m\u001b[m   \u001b[34m9023102\u001b[m\u001b[m   \u001b[34m9889544\u001b[m\u001b[m\n",
      "\u001b[34m1635604\u001b[m\u001b[m   \u001b[34m3084846\u001b[m\u001b[m   \u001b[34m4091474\u001b[m\u001b[m   \u001b[34m5013589\u001b[m\u001b[m   \u001b[34m6360867\u001b[m\u001b[m   \u001b[34m7568597\u001b[m\u001b[m   \u001b[34m9023841\u001b[m\u001b[m   \u001b[34m9909448\u001b[m\u001b[m\n",
      "\u001b[34m1711090\u001b[m\u001b[m   \u001b[34m3102543\u001b[m\u001b[m   \u001b[34m4101394\u001b[m\u001b[m   \u001b[34m5030375\u001b[m\u001b[m   \u001b[34m6395760\u001b[m\u001b[m   \u001b[34m7606018\u001b[m\u001b[m   \u001b[34m9026274\u001b[m\u001b[m   \u001b[34m9930257\u001b[m\u001b[m\n",
      "\u001b[34m1784075\u001b[m\u001b[m   \u001b[34m3137570\u001b[m\u001b[m   \u001b[34m4135058\u001b[m\u001b[m   \u001b[34m5158901\u001b[m\u001b[m   \u001b[34m6404099\u001b[m\u001b[m   \u001b[34m7620567\u001b[m\u001b[m   \u001b[34m9042627\u001b[m\u001b[m   \u001b[34m9931234\u001b[m\u001b[m\n",
      "\u001b[34m1966913\u001b[m\u001b[m   \u001b[34m3165520\u001b[m\u001b[m   \u001b[34m4169074\u001b[m\u001b[m   \u001b[34m5160587\u001b[m\u001b[m   \u001b[34m6424373\u001b[m\u001b[m   \u001b[34m7658420\u001b[m\u001b[m   \u001b[34m9053120\u001b[m\u001b[m   \u001b[34m9939055\u001b[m\u001b[m\n",
      "\u001b[34m1984879\u001b[m\u001b[m   \u001b[34m3169275\u001b[m\u001b[m   \u001b[34m4200389\u001b[m\u001b[m   \u001b[34m5181071\u001b[m\u001b[m   \u001b[34m6433158\u001b[m\u001b[m   \u001b[34m7658604\u001b[m\u001b[m   \u001b[34m9125564\u001b[m\u001b[m   DATS.json\n",
      "\u001b[34m2017146\u001b[m\u001b[m   \u001b[34m3191214\u001b[m\u001b[m   \u001b[34m4210489\u001b[m\u001b[m   \u001b[34m5184448\u001b[m\u001b[m   \u001b[34m6445003\u001b[m\u001b[m   \u001b[34m7672530\u001b[m\u001b[m   \u001b[34m9155520\u001b[m\u001b[m   README.md\n",
      "\u001b[34m2111048\u001b[m\u001b[m   \u001b[34m3195342\u001b[m\u001b[m   \u001b[34m4280226\u001b[m\u001b[m   \u001b[34m5219094\u001b[m\u001b[m   \u001b[34m6519252\u001b[m\u001b[m   \u001b[34m7678521\u001b[m\u001b[m   \u001b[34m9191774\u001b[m\u001b[m   logo.png\n",
      "\u001b[34m2137252\u001b[m\u001b[m   \u001b[34m3230637\u001b[m\u001b[m   \u001b[34m4317780\u001b[m\u001b[m   \u001b[34m5261010\u001b[m\u001b[m   \u001b[34m6605596\u001b[m\u001b[m   \u001b[34m7755697\u001b[m\u001b[m   \u001b[34m9249727\u001b[m\u001b[m\n",
      "\u001b[34m2161762\u001b[m\u001b[m   \u001b[34m3276299\u001b[m\u001b[m   \u001b[34m4329125\u001b[m\u001b[m   \u001b[34m5352582\u001b[m\u001b[m   \u001b[34m6690963\u001b[m\u001b[m   \u001b[34m7760229\u001b[m\u001b[m   \u001b[34m9327302\u001b[m\u001b[m\n",
      "\u001b[34m2332918\u001b[m\u001b[m   \u001b[34m3301724\u001b[m\u001b[m   \u001b[34m4351499\u001b[m\u001b[m   \u001b[34m5353353\u001b[m\u001b[m   \u001b[34m6704921\u001b[m\u001b[m   \u001b[34m7819541\u001b[m\u001b[m   \u001b[34m9360002\u001b[m\u001b[m\n",
      "\u001b[34m2336041\u001b[m\u001b[m   \u001b[34m3343577\u001b[m\u001b[m   \u001b[34m4360628\u001b[m\u001b[m   \u001b[34m5360989\u001b[m\u001b[m   \u001b[34m6743559\u001b[m\u001b[m   \u001b[34m7855613\u001b[m\u001b[m   \u001b[34m9466302\u001b[m\u001b[m\n",
      "\u001b[34m2345993\u001b[m\u001b[m   \u001b[34m3360165\u001b[m\u001b[m   \u001b[34m4365974\u001b[m\u001b[m   \u001b[34m5452448\u001b[m\u001b[m   \u001b[34m6781586\u001b[m\u001b[m   \u001b[34m7863306\u001b[m\u001b[m   \u001b[34m9488568\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "#Move to the directory where you want to download the data (I created a special folder called data_CONP/)\n",
    "\n",
    "##%cd /Users/stong3/Desktop/data_CONP/\n",
    "#!datalad install https://github.com/CONP-PCNO/conp-dataset.git\n",
    "\n",
    "#Once installed, you can go in the directory and install the Prevent-AD dataset\n",
    "##%cd /Users/stong3/Desktop/data_CONP/conp-dataset/\n",
    "##!datalad install projects/preventad-open\n",
    "\n",
    "#You can now navigate to the project directory\n",
    "##%cd /Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/\n",
    "\n",
    "#You should be able to see the list of subjects within the project\n",
    "##!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Data download\n",
    "\n",
    "We can now see that we can access all the subjects within the Prevent-AD project. All the subjects are divided in the following manner are divided in sessions and then in an image folder.\n",
    "\n",
    "For this pre-processing tutorial, we will only use 10 subjects from whom we have the Baseline and the 12 months follow-up. In total, we will have 20 fMRI scans to pre-process. For simplicity, I took the first 10 subjects where:\n",
    "- An anatomical scan (T1w) was available at baseline\n",
    "- A resting-state functional MRI (rest BOLD) was available at baseline\n",
    "- An anatomical scan (T1w) was available at 12 months\n",
    "- A resting-state functional MRI (rest BOLD) was available at 12 months\n",
    "\n",
    "The way Datalad downloads data is by using the following command: ```datalad get <filepath>```. \n",
    "\n",
    "In our case, based on the folders, we will require the following subjects (datalad commands below) and will only download these to reduce the data to analyze:\n",
    "- 1004359 (Done) \n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1004359/```\n",
    "- 1016072 (Done) \n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1016072/```\n",
    "- 1072774 (Done) \n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1072774/```\n",
    "- 1076159 (Done) \n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1076159/```\n",
    "- 1154932 (Done)\n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1154932/```\n",
    "- 1176949 (Done)\n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1176949/```\n",
    "- 1177880 (Done)\n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1177880/```\n",
    "- 1284264 (Done)\n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1284264/```\n",
    "- 1322140 (Done)\n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1322140/```\n",
    "- 1346022 (Done)\n",
    "```/Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/1346022/```\n",
    "\n",
    "The first time this is done, there will be a prompt to enter a username and password (twice). These are the same as the ones create to access LORIS.\n",
    "\n",
    "The data is downloaded directly in the CONP folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Next steps\n",
    "\n",
    "Ok. So our data is downloaded. Are we ready for running fMRIPrep? Not quite.\n",
    "\n",
    "When looking at the data, we can see that in each visits, we have a folder called \"images\", in which all the different images are stored in a single folder. Furthermore, each image is succeeded by the .mnc extension... Yikes!\n",
    "\n",
    "We still have to fix a few things before fMRIPrep can be run. Based on the documentation from fMRIPrep, we need:\n",
    "1) To convert our .mnc images to a .nii format. \n",
    "2) To make our data compliant with the BIDS organization.\n",
    "\n",
    "Step 1) will be done with the mnc2nii tool available in the minc-toolkit. Step 2) will be done using a custom bash script and the bids-validator.\n",
    "\n",
    "To ease the process, I move the 10 participants to a different folder on my Desktop called \"bhs_project\". In this, I create a subdirectory called sourcedata where the folders are transferred. Then, I create a directory called \"rawdata\" where transformation of the data will occur.\n",
    "\n",
    "Note that for all the code below, the Bash code is preceeded by ```!```. Sometimes, it is possible that to work within Jupyter, we need to preceed the code by a ```%``` Make sure to change the paths to the appropriate one on your computer so that it works appropriately. You can also copy the code to your terminal, as it doesn't always work well directly on Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Ok so first, just figuring out where we are\n",
    "!pwd\n",
    "%cd /Users/stong3/Desktop #Moving back to the desktop\n",
    "\n",
    "#So now that I am on the Desktop, I create the folders \n",
    "!mkdir bhs_project/ #Creating the main folder to put the data in\n",
    "%cd /Users/stong3/Desktop/bhs_project/\n",
    "!mkdir sourcedata/ #Creating a \"sourcedata\" repository where all the untouched data is stored\n",
    "!mkdir rawdata/ #Creating a \"rawdata\" repository where we will do the transformations\n",
    "!mkdir derivatives/ #This will come late in the process, once we pre-process the data\n",
    "\n",
    "#Then, we go back to the directory where the data is stored (i.e. conp_dataset). So in our case:\n",
    "%cd /Users/stong3/Desktop/data_CONP/conp-dataset/projects/preventad-open/\n",
    "#Now we copy the 10 subjects we need to the folder we just created. Careful! This command can take a long time so make sure the path is correctly specified\n",
    "!cp -r 1004359 1016072 1072774 1076159 1154932 1176949 1177880 1284264 1322140 1346022 /Users/stong3/Desktop/bhs_project/sourcedata/\n",
    "\n",
    "#Now we copy the 10 subjects we need, but to the rawdata folder WITHOUT the images inside (this will become useful in the .mnc format conversion).\n",
    "#However, we have .json files that we might wanna keep for later (will be useful for BIDS). We can use the following:\n",
    "!find /Users/stong3/Desktop/bhs_project/sourcedata -name '*.json' | cpio -pdm /Users/stong3/Desktop/bhs_project/rawdata\n",
    "\n",
    "#This finds all the .json files within the selected directory and then pipes the input into cpio which copies the directories and the files.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 - Converting the images from .mnc to .nii individually\n",
    "\n",
    "To convert the images, we can use the mnc2nii tool from the minc-toolkit. The first step is to actually get the toolkit. To do so, we use a Docker image using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull nistmni/minc-toolkit:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker works as a \"mini-computer environment\" separate from your computer. So before running the actual code, we need to guide Docker to the appropriate locations on our computer and set-up mounts (i.e. integrating the computer's paths in the container). First, you can run the container by itself without mounting anything inside to see how it is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The -it option makes the container interactive (i.e. you can access it in the bash terminal directly)\n",
    "#The --rm option remove the current environment to insure that nothing LEAKS inside the computer\n",
    "\n",
    "!docker run -it --rm \\\n",
    "nistmni/minc-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can simply type ```exit``` to exit the Docker. \n",
    "\n",
    "The entry point of the container when we access doesn't show anything... Well that's ok. You can do ```cd /``` to access the root of the container. You will see a LOT of folders. They are mostly the software needed for the minc-toolbox. \n",
    "\n",
    "Ok, now we need to \"link\" our computer to the container. With docker, we can do this using the option ```-v <filepath>```. After giving the path inside our computer, we give the path that Docker uses IN the container. The best way I methaphored this in my mind is that it acts as \"entry\" and \"exit\" doors to and from the container.\n",
    "\n",
    "To insure that Docker doesn't modify the original files in \"sourcedata\", we add the ```:ro``` option after the paths which tells Docker that it cannot modify these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm \\\n",
    "-v /Users/stong3/Desktop/bhs_project/sourcedata:/files_to_convert:ro \\\n",
    "-v /Users/stong3/Desktop/bhs_project/rawdata:/converted_files \\\n",
    "nistmni/minc-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! We are now in the container! If we do ```cd /``` and ```ls```, we see our two folders (\"files_to_convert\" and \"converted_files\") in the Docker container along with all the other \"software\" folders. \n",
    "\n",
    "Yay! Now we are ready to convert our files!\n",
    "\n",
    "The code is quite straight forward. Inside the container, you type the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnc2nii -<format_desired> <path/to/file.mnc> <path/to/new_file.nii>\n",
    "#Note that you can give the name of the new file in the path of the .nii file\n",
    "!mnc2nii -nii /files_to_convert/1004359/PREBL00/images/preventad_1004359_PREBL00_t1w_001_t1w-defaced_001.mnc /converted_files/preventad_1004359_PREBL00_t1w_001_t1w-defaced_001.nii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! We see an output, that I have no idea what it means... But I guess \"reconstruction\" is reassuring? \n",
    "\n",
    "Once the process is done, we can check the images both inside and out the container... But now it's a bit of a long process to do the mnc2nii x20 times... Specifying a specific path EVERY time. Maybe there's a way to simplify it? and maybe there is even a way to transform the data to .nii format AND in Bids at the same time??\n",
    "\n",
    "Well why not! We just need to tweak our approach a little bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 - Converting the images in loop for all subjects form .mnc to .nii in BIDS format\n",
    "\n",
    "So the plan is to create a custom bash script that we will use in the Docker container to:\n",
    "1) Move to the correct folder to launch the job\n",
    "2) Loop over all subjects in the directory\n",
    "3) Create new directories to prepare for the BIDS formatted data\n",
    "4) Launch the conversion using mnc2nii for all subjects available\n",
    "\n",
    "Note that I composed this script in VSCode and store the script in a separate directory. This directory also needs to be mounted in Docker. The script below, is available on Github of this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "#First, inside the container, we need to move to the directory where the files to convert are stored. We can force this with a cd command.\n",
    "\n",
    "cd /files_to_convert\n",
    "\n",
    "#The loop starts below\n",
    "for folders in */; do #This starts the loop. For each folder in the files_to_convert directory, do the following:\n",
    "    subj=\"${folders%/}\" #Take the name of the folder, strip the \"/\" and assign this value to a variable \"subj\" (subject)\n",
    "    echo \"--------------------------\"\n",
    "    echo \"--------------------------\"\n",
    "    echo \"Processing subject ${subj}\" #This is for us: it simply echoes which subject we are currently processing in ther terminal.\n",
    "    echo \"--------------------------\"\n",
    "    #We need to prepare new directories for the new BIDS formatted files. \n",
    "    #The format according to BIDS specification is: rawdata/<subject>/<session>/<modality>\n",
    "        #The loop will take care of the \"subject\" part using the $subj variable\n",
    "        #We create 2 sub-directories for each subject (session 1 - baseline, and session 2 - 12 months)\n",
    "        #In each sub-directory, for each session, we create an anat and a func folder\n",
    "    echo \"--------------------------\"\n",
    "    echo \"Creating...\"\n",
    "    mkdir -p /converted_files/sub-${subj}/ses-BL00/anat\n",
    "    echo \"...Directory for ${subj} converted anat BL created (session 1)\"\n",
    "    mkdir -p /converted_files/sub-${subj}/ses-FU12/anat\n",
    "    echo \"...Directory for ${subj} converted anat FU12 created (session 2)\"\n",
    "    mkdir -p /converted_files/sub-${subj}/ses-BL00/func #The p create intermediate directories too.\n",
    "    echo \"...Directory for ${subj} converted func BL created (session 1)\"\n",
    "    mkdir -p /converted_files/sub-${subj}/ses-FU12/func\n",
    "    echo \"...Directory for ${subj} converted func FU12 created (session 2)\"\n",
    "\n",
    "    echo \" \"\n",
    "    echo \"Starting conversion...\"\n",
    "    echo \" \"\n",
    "    #We have a little problem with the visit labels. The dataset includes visit from 2 different visit labels, either PRE or NAP. We can use a bash operator \"||\" to lauch\n",
    "    ## the same task with NAP instead of PRE if the mnc2nii cannot find a PRE visit.\n",
    "    echo \"--------------------------------\"\n",
    "    echo \"Conversion - Baseline Structural\"\n",
    "    echo \"--------------------------------\"\n",
    "\n",
    "    echo \"Testing if the subject has a PRE visit\"\n",
    "        #If the line below fails, the || operator executes the next line. Since we use line break operators, the echo and next mnc2nii commands count as a single command.\n",
    "    mnc2nii -nii ${subj}/PREBL00/images/preventad_${subj}_PREBL00_t1w_001_t1w-defaced_001.mnc /converted_files/sub-${subj}/ses-BL00/anat/sub-${subj}_ses-BL00_T1w.nii || \\\n",
    "    ( echo \"There is no PRE visit. Checking for a NAP visit...\" && \\\n",
    "    mnc2nii -nii ${subj}/NAPBL00/images/preventad_${subj}_NAPBL00_t1w_001_t1w-defaced_001.mnc /converted_files/sub-${subj}/ses-BL00/anat/sub-${subj}_ses-BL00_T1w.nii )\n",
    "\n",
    "    echo \"--------------------------------\"\n",
    "    echo \"Conversion - 12 months Structural\"\n",
    "    echo \"--------------------------------\"\n",
    "\n",
    "    echo \"Testing if the subject has a PRE visit\"\n",
    "    mnc2nii -nii ${subj}/PREFU12/images/preventad_${subj}_PREFU12_t1w_001_t1w-defaced_001.mnc /converted_files/sub-${subj}/ses-FU12/anat/sub-${subj}_ses-FU12_T1w.nii || \\\n",
    "    ( echo \"There is no PRE visit. Checking for a NAP visit...\" && \\\n",
    "    mnc2nii -nii ${subj}/NAPFU12/images/preventad_${subj}_NAPFU12_t1w_001_t1w-defaced_001.mnc /converted_files/sub-${subj}/ses-FU12/anat/sub-${subj}_ses-FU12_T1w.nii )\n",
    "\n",
    "    echo \"--------------------------------\"\n",
    "    echo \"Conversion - Baseline Functional\"\n",
    "    echo \"--------------------------------\"\n",
    "\n",
    "    echo \"Testing if the subject has a PRE visit\"\n",
    "    mnc2nii -nii ${subj}/PREBL00/images/preventad_${subj}_PREBL00_bold_001.mnc /converted_files/sub-${subj}/ses-BL00/func/sub-${subj}_ses-BL00_task-rest_bold.nii || \\\n",
    "    ( echo \"There is no PRE visit. Checking for a NAP visit...\" ; \\\n",
    "    mnc2nii -nii ${subj}/NAPBL00/images/preventad_${subj}_NAPBL00_bold_001.mnc /converted_files/sub-${subj}/ses-BL00/func/sub-${subj}_ses-BL00_task-rest_bold.nii )\n",
    "\n",
    "    echo \"--------------------------------\"\n",
    "    echo \"Conversion - 12 months Functional\"\n",
    "    echo \"--------------------------------\"\n",
    "\n",
    "    echo \"Testing if the subject has a PRE visit\"\n",
    "    mnc2nii -nii ${subj}/PREFU12/images/preventad_${subj}_PREFU12_bold_001.mnc /converted_files/sub-${subj}/ses-FU12/func/sub-${subj}_ses-FU12_task-rest_bold.nii || \\\n",
    "    ( echo \"There is no PRE visit. Checking for a NAP visit...\" ; \\\n",
    "    mnc2nii -nii ${subj}/NAPFU12/images/preventad_${subj}_NAPFU12_bold_001.mnc /converted_files/sub-${subj}/ses-FU12/func/sub-${subj}_ses-FU12_task-rest_bold.nii )\n",
    "    \n",
    "    echo \"Conversion done for subject ${subj}! \"\n",
    "    echo \" \"\n",
    "done #Don't forget to tell the loop to close!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this script, I would recommend lauching the Docker image this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm \\\n",
    "    -w=\"/script_conversion\" \\\n",
    "    -v /Users/stong3/Desktop/bhs_project/sourcedata:/files_to_convert:ro \\\n",
    "    -v /Users/stong3/Desktop/bhs_project/rawdata:/converted_files \\\n",
    "    -v /Users/stong3/Desktop/BHS2020_Project/01_script_conversion_mnc2bids:/script_conversion \\\n",
    "    nistmni/minc-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, the script would not launch from outside the container. As such, I ran the Docker command above and then I simply ran ```sh mnc2bids.sh```, after telling Docker to start its run in the 'script_conversion' folder, which contained the mnc2bids script from the mount.\n",
    "\n",
    "Ultimately, after the conversion ran, I thought I was ready. The conversion gave us this nice folder (where I created the dataset_description.json manually): "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rawdata\n",
    "├── dataset_description.json\n",
    "├── sub-1004359\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1004359_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1004359_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1004359_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1004359_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1016072\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1016072_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1016072_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1016072_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1016072_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1072774\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1072774_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1072774_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1072774_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1072774_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1076159\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1076159_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1076159_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1076159_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1076159_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1154932\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1154932_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1154932_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1154932_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1154932_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1176949\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1176949_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1176949_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1176949_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1176949_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1177880\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1177880_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1177880_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1177880_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1177880_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1284264\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1284264_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1284264_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1284264_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1284264_ses-FU12_task-rest_bold.nii\n",
    "├── sub-1322140\n",
    "│   ├── ses-BL00\n",
    "│   │   ├── anat\n",
    "│   │   │   └── sub-1322140_ses-BL00_T1w.nii\n",
    "│   │   └── func\n",
    "│   │       └── sub-1322140_ses-BL00_task-rest_bold.nii\n",
    "│   └── ses-FU12\n",
    "│       ├── anat\n",
    "│       │   └── sub-1322140_ses-FU12_T1w.nii\n",
    "│       └── func\n",
    "│           └── sub-1322140_ses-FU12_task-rest_bold.nii\n",
    "└── sub-1346022\n",
    "    ├── ses-BL00\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-1346022_ses-BL00_T1w.nii\n",
    "    │   └── func\n",
    "    │       └── sub-1346022_ses-BL00_task-rest_bold.nii\n",
    "    └── ses-FU12\n",
    "        ├── anat\n",
    "        │   └── sub-1346022_ses-FU12_T1w.nii\n",
    "        └── func\n",
    "            └── sub-1346022_ses-FU12_task-rest_bold.nii "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 - BIDS validation\n",
    "\n",
    "It is in this step that things started to derail a little bit. I first decided to use ```pybids``` to check if everything was in order. Using pybids, I am able to obtain subjects, sessions and task for my subjects. But the get_collections was not working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004359', '1016072', '1072774', '1076159', '1154932', '1176949', '1177880', '1284264', '1322140', '1346022']\n",
      "['BL00', 'FU12']\n",
      "['rest']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1004359'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-68bda96ab7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcollections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/bids/layout/layout.py\u001b[0m in \u001b[0;36mget_collections\u001b[0;34m(self, level, types, variables, merge, sampling_rate, skip_empty, **kwargs)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mbids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         index = load_variables(self, types=types, levels=level,\n\u001b[0;32m-> 1114\u001b[0;31m                                skip_empty=skip_empty, **kwargs)\n\u001b[0m\u001b[1;32m   1115\u001b[0m         return index.get_collections(level, variables, merge,\n\u001b[1;32m   1116\u001b[0m                                      sampling_rate=sampling_rate)\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/bids/variables/io.py\u001b[0m in \u001b[0;36mload_variables\u001b[0;34m(layout, types, levels, skip_empty, dataset, scope, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;34m'dataset'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'participants'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             }\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/bids/variables/io.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;34m'dataset'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'participants'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             }\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1004359'"
     ]
    }
   ],
   "source": [
    "from bids import BIDSLayout\n",
    "from bids.reports import BIDSReport\n",
    "layout = BIDSLayout('/Users/stong3/Desktop/bhs_project/rawdata')\n",
    "report = BIDSReport(layout)\n",
    "\n",
    "\n",
    "subjects = layout.get_subjects()\n",
    "print(subjects)\n",
    "sessions = layout.get_sessions()\n",
    "print(sessions)\n",
    "tasks = layout.get_tasks()\n",
    "print(tasks)\n",
    "collections = layout.get_collections(level=subjects, extension='nii')[0].filename\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I simply decided to run the bids validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondac9b5ed61f5c54c1fafa453bcab913e9f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
